{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradients are different at (0, 0). Analytic: 0.00002, Numeric: 0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradients are different at (0, 1). Analytic: -0.00123, Numeric: -0.00112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 46.899587, Train accuracy: 0.268222, val accuracy: 0.269000\n",
      "Loss: 36.054748, Train accuracy: 0.468778, val accuracy: 0.457000\n",
      "Loss: 27.252608, Train accuracy: 0.599222, val accuracy: 0.582000\n",
      "Loss: 23.632900, Train accuracy: 0.650444, val accuracy: 0.639000\n",
      "Loss: 19.627481, Train accuracy: 0.677333, val accuracy: 0.648000\n",
      "Loss: 27.984155, Train accuracy: 0.712667, val accuracy: 0.688000\n",
      "Loss: 13.220821, Train accuracy: 0.700889, val accuracy: 0.665000\n",
      "Loss: 15.152768, Train accuracy: 0.710111, val accuracy: 0.657000\n",
      "Loss: 28.111143, Train accuracy: 0.694778, val accuracy: 0.649000\n",
      "Loss: 19.471147, Train accuracy: 0.752667, val accuracy: 0.690000\n",
      "Loss: 23.205527, Train accuracy: 0.728556, val accuracy: 0.654000\n",
      "Loss: 10.148457, Train accuracy: 0.775111, val accuracy: 0.701000\n",
      "Loss: 19.280205, Train accuracy: 0.789778, val accuracy: 0.701000\n",
      "Loss: 20.116878, Train accuracy: 0.781667, val accuracy: 0.696000\n",
      "Loss: 25.778132, Train accuracy: 0.801333, val accuracy: 0.718000\n",
      "Loss: 15.128331, Train accuracy: 0.811444, val accuracy: 0.715000\n",
      "Loss: 15.021201, Train accuracy: 0.812444, val accuracy: 0.711000\n",
      "Loss: 19.700239, Train accuracy: 0.806111, val accuracy: 0.699000\n",
      "Loss: 13.080617, Train accuracy: 0.801556, val accuracy: 0.713000\n",
      "Loss: 16.660734, Train accuracy: 0.780444, val accuracy: 0.688000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-3)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x126834cc348>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.268685, Train accuracy: 0.244222, val accuracy: 0.253000\n",
      "Loss: 34.371266, Train accuracy: 0.388889, val accuracy: 0.415000\n",
      "Loss: 36.492828, Train accuracy: 0.446444, val accuracy: 0.457000\n",
      "Loss: 37.046245, Train accuracy: 0.511222, val accuracy: 0.525000\n",
      "Loss: 39.233755, Train accuracy: 0.495333, val accuracy: 0.506000\n",
      "Loss: 39.045584, Train accuracy: 0.579444, val accuracy: 0.574000\n",
      "Loss: 34.887343, Train accuracy: 0.548556, val accuracy: 0.558000\n",
      "Loss: 33.599379, Train accuracy: 0.556889, val accuracy: 0.556000\n",
      "Loss: 37.273219, Train accuracy: 0.514000, val accuracy: 0.493000\n",
      "Loss: 34.360432, Train accuracy: 0.567556, val accuracy: 0.565000\n",
      "Loss: 36.836394, Train accuracy: 0.608222, val accuracy: 0.601000\n",
      "Loss: 34.694721, Train accuracy: 0.593778, val accuracy: 0.564000\n",
      "Loss: 35.309617, Train accuracy: 0.591222, val accuracy: 0.570000\n",
      "Loss: 36.773243, Train accuracy: 0.637444, val accuracy: 0.623000\n",
      "Loss: 34.690199, Train accuracy: 0.589000, val accuracy: 0.560000\n",
      "Loss: 36.840934, Train accuracy: 0.563667, val accuracy: 0.574000\n",
      "Loss: 35.840167, Train accuracy: 0.607556, val accuracy: 0.607000\n",
      "Loss: 34.307293, Train accuracy: 0.602000, val accuracy: 0.592000\n",
      "Loss: 32.058030, Train accuracy: 0.582778, val accuracy: 0.587000\n",
      "Loss: 30.994244, Train accuracy: 0.606556, val accuracy: 0.570000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 43.313023, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 47.288580, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 40.594084, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 43.847434, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 45.314180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 44.346688, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 43.432561, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 45.295835, Train accuracy: 0.233778, val accuracy: 0.230000\n",
      "Loss: 40.838456, Train accuracy: 0.268111, val accuracy: 0.271000\n",
      "Loss: 40.169634, Train accuracy: 0.312667, val accuracy: 0.321000\n",
      "Loss: 38.269435, Train accuracy: 0.352556, val accuracy: 0.355000\n",
      "Loss: 31.911152, Train accuracy: 0.402000, val accuracy: 0.400000\n",
      "Loss: 32.010635, Train accuracy: 0.441556, val accuracy: 0.441000\n",
      "Loss: 26.236755, Train accuracy: 0.467444, val accuracy: 0.477000\n",
      "Loss: 34.011911, Train accuracy: 0.507111, val accuracy: 0.505000\n",
      "Loss: 25.388382, Train accuracy: 0.537556, val accuracy: 0.533000\n",
      "Loss: 18.784254, Train accuracy: 0.552556, val accuracy: 0.550000\n",
      "Loss: 27.671250, Train accuracy: 0.578222, val accuracy: 0.575000\n",
      "Loss: 19.735307, Train accuracy: 0.602000, val accuracy: 0.595000\n",
      "Loss: 21.954682, Train accuracy: 0.615222, val accuracy: 0.614000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.534389, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.475800, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.557857, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.484084, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.442495, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.345405, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.393803, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.381885, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: 11.343380, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.226506, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.074267, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.204587, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.292691, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.338798, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.000228, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 11.228572, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.129089, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.202262, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.077976, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 10.635829, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 11.190024, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 9.802864, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 9.348411, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 11.206247, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 9.934021, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 5.846426, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 9.868810, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 8.567597, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 9.354371, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 8.668006, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 10.420494, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 8.920421, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 10.332307, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 9.345828, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 9.349754, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 7.089963, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 6.902057, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 5.908919, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 8.647670, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 8.854655, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 7.125501, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 8.619432, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 8.180330, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.586097, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.852229, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 6.949628, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 5.849216, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.281771, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 5.670987, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 9.908363, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 4.557506, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 4.941305, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 6.827540, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 7.751801, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 8.545411, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 5.949655, Train accuracy: 0.600000, val accuracy: 0.133333\n",
      "Loss: 7.908461, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 5.750691, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 5.862978, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 6.360985, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 6.509922, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 5.236790, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 4.311914, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 4.183428, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 3.900088, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.494837, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.467391, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 3.724757, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.200179, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 7.661515, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.412671, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.268207, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 4.157603, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.120181, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 2.875022, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.876628, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 3.482523, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.069628, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 5.025481, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 5.251073, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.816591, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 6.712313, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.206952, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.418561, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.628598, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.142965, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 5.273804, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.186101, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.110785, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.077071, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.354468, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.876275, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.826730, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.754577, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.469498, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.783869, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.021727, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.803424, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.453053, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 2.152408, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.995981, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 4.831941, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.360195, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 3.596350, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.121356, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.535437, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.442744, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 4.118938, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 3.958967, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 3.994673, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.979054, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.864464, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 4.267702, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.412257, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.952675, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.193707, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.385350, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.750283, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.236510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.276579, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.533956, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.302314, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.196851, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.411942, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.381874, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.521608, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.288003, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.861027, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.152538, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.469199, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.215379, Train accuracy: 0.933333, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.101211, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.857547, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.448747, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.638670, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 3.678959, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.604081, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.318802, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.329901, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.278808, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.599002, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.980681, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.525937, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.193842, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.340054, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.210981, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.283495, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.301281, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.450845, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.988848, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-2)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-2, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06-0.06-256\n",
      "Loss: 11.562751, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.442711, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.242043, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.066825, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.104100, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 10.905264, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 8.172086, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 12.720833, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 10.399654, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 8.469296, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 8.961447, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 11.449193, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 6.612230, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.483799, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 5.377295, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.949387, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 5.016604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 6.550292, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.204860, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 2.417701, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "0.06-0.06-512\n",
      "Loss: 11.673944, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11.816964, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 10.855028, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 10.785621, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 9.067352, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 8.835664, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: 7.228997, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 10.843957, Train accuracy: 0.333333, val accuracy: 0.200000\n",
      "Loss: 6.974068, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 6.802162, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 9.521159, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 10.174015, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 19.018532, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 15.127720, Train accuracy: 0.466667, val accuracy: 0.133333\n",
      "Loss: 6.323340, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.591151, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 5.983033, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 7.238306, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 3.398120, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 2.264437, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "0.06-0.01-256\n",
      "Loss: 11.585675, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.626470, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 10.989314, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 11.663609, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 11.086510, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 10.594260, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 11.227848, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 14.097959, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: 12.032678, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 13.969650, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 29.922002, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 10.790099, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 14.155312, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 28.290595, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 13.843250, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 4.774539, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 9.900644, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 6.084096, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 2.571341, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.544885, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "0.06-0.01-512\n",
      "Loss: 11.597594, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 11.396039, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 11.132223, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 9.639668, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 10.916838, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 5.536721, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 8.045706, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 8.144550, Train accuracy: 0.333333, val accuracy: 0.200000\n",
      "Loss: 11.652748, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: 41.357466, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 45.774450, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 45.345437, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 21.724775, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 30.672999, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 14.605548, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 9.221088, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 4.089433, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 10.161704, Train accuracy: 0.866667, val accuracy: 0.133333\n",
      "Loss: 4.122685, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.754724, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "0.1-0.06-256\n",
      "Loss: 11.658403, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.000848, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 11.941983, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 9.852697, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 49.746581, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: 32.240744, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: 25.587189, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 497.885000, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.000000, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.000000\n",
      "0.1-0.06-512\n",
      "Loss: 11.703148, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.233549, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 14.101715, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "Loss: 8.524751, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 31.739119, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 21.607263, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 18.770133, Train accuracy: 0.333333, val accuracy: 0.133333\n",
      "Loss: 107.047257, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 215.543968, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: 270.900268, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1255.806828, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 1076.876909, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.200000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "0.1-0.01-256\n",
      "Loss: 11.639171, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 11.358533, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11.308696, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11.663478, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 9.468402, Train accuracy: 0.333333, val accuracy: 0.066667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 40.319042, Train accuracy: 0.266667, val accuracy: 0.133333\n",
      "Loss: 42.765354, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.000000, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.133333, val accuracy: 0.266667\n",
      "0.1-0.01-512\n",
      "Loss: 11.639813, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11.591682, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 11.779890, Train accuracy: 0.133333, val accuracy: 0.133333\n",
      "Loss: 11.520942, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 13.080443, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 23.927707, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 11.541778, Train accuracy: 0.200000, val accuracy: 0.200000\n",
      "Loss: 10.192105, Train accuracy: 0.400000, val accuracy: 0.133333\n",
      "Loss: 12.709656, Train accuracy: 0.533333, val accuracy: 0.133333\n",
      "Loss: 14.320674, Train accuracy: 0.333333, val accuracy: 0.200000\n",
      "Loss: 365.169126, Train accuracy: 0.066667, val accuracy: 0.133333\n",
      "Loss: 677.363653, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.066667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.266667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.200000, val accuracy: 0.000000\n",
      "Loss: inf, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: inf, Train accuracy: 0.266667, val accuracy: 0.200000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "params = {\n",
    "    \"lr\": [0.06, 0.1],\n",
    "    \"reg\": [0.06, 0.01],\n",
    "    \"hlsize\": [256, 512]\n",
    "}\n",
    "for lr in params[\"lr\"]:\n",
    "    for reg in params[\"reg\"]:\n",
    "        for hlsize in params[\"hlsize\"]:\n",
    "            print(f\"{lr}-{reg}-{hlsize}\")\n",
    "            model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hlsize, reg = reg)\n",
    "            dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "            trainer = Trainer(model, dataset, SGD(), learning_rate=lr, num_epochs=20, batch_size=5)\n",
    "            loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0.0001-0.01-0.9-64-5-128\n",
      "Loss: 86.887477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 92.746268, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 89.118072, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.450312, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 79.989343, Train accuracy: 0.233222, val accuracy: 0.237000\n",
      "Model 0.0001-0.01-0.9-64-5-256\n",
      "Loss: 92.123335, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 89.830825, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 89.042661, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 85.983626, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 93.065057, Train accuracy: 0.215111, val accuracy: 0.227000\n",
      "Model 0.0001-0.01-0.9-128-5-128\n",
      "Loss: 89.148586, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 86.041209, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 85.420426, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.907107, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 78.990196, Train accuracy: 0.241444, val accuracy: 0.243000\n",
      "Model 0.0001-0.01-0.9-128-5-256\n",
      "Loss: 89.648457, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.844546, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.360151, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 81.892398, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.567303, Train accuracy: 0.216111, val accuracy: 0.219000\n",
      "Model 0.0001-0.001-0.9-64-5-128\n",
      "Loss: 92.543822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 91.079191, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.679815, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.362617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 83.426563, Train accuracy: 0.247111, val accuracy: 0.249000\n",
      "Model 0.0001-0.001-0.9-64-5-256\n",
      "Loss: 92.293542, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 92.588801, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.452862, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 89.402050, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 90.729676, Train accuracy: 0.207778, val accuracy: 0.214000\n",
      "Model 0.0001-0.001-0.9-128-5-128\n",
      "Loss: 90.712159, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.694844, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 89.333249, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 86.918336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 79.601024, Train accuracy: 0.247444, val accuracy: 0.252000\n",
      "Model 0.0001-0.001-0.9-128-5-256\n",
      "Loss: 90.102426, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.816941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.120428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 85.638629, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.218800, Train accuracy: 0.204778, val accuracy: 0.213000\n",
      "Model 0.0001-0.0001-0.9-64-5-128\n",
      "Loss: 85.855182, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 92.664538, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.404596, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 90.959474, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 80.547916, Train accuracy: 0.244333, val accuracy: 0.247000\n",
      "Model 0.0001-0.0001-0.9-64-5-256\n",
      "Loss: 94.485882, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 86.349598, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.384765, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 92.091700, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 82.858156, Train accuracy: 0.207333, val accuracy: 0.215000\n",
      "Model 0.0001-0.0001-0.9-128-5-128\n",
      "Loss: 88.770131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 91.494903, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 86.593755, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 88.340504, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 83.438742, Train accuracy: 0.235000, val accuracy: 0.238000\n",
      "Model 0.0001-0.0001-0.9-128-5-256\n",
      "Loss: 88.452262, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 84.306582, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 85.287160, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 87.071159, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 85.930928, Train accuracy: 0.207111, val accuracy: 0.217000\n",
      "Model 0.00055-0.01-0.9-64-5-128\n",
      "Loss: 89.951975, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 79.626584, Train accuracy: 0.359111, val accuracy: 0.353000\n",
      "Loss: 43.334375, Train accuracy: 0.544222, val accuracy: 0.541000\n",
      "Loss: 47.784525, Train accuracy: 0.605556, val accuracy: 0.608000\n",
      "Loss: 44.271547, Train accuracy: 0.665000, val accuracy: 0.634000\n",
      "Model 0.00055-0.01-0.9-64-5-256\n",
      "Loss: 89.438433, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 76.766780, Train accuracy: 0.282111, val accuracy: 0.293000\n",
      "Loss: 68.257409, Train accuracy: 0.437556, val accuracy: 0.444000\n",
      "Loss: 49.262670, Train accuracy: 0.582444, val accuracy: 0.578000\n",
      "Loss: 47.582591, Train accuracy: 0.571111, val accuracy: 0.564000\n",
      "Model 0.00055-0.01-0.9-128-5-128\n",
      "Loss: 90.014083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 76.466616, Train accuracy: 0.409000, val accuracy: 0.415000\n",
      "Loss: 55.920504, Train accuracy: 0.547111, val accuracy: 0.543000\n",
      "Loss: 53.052189, Train accuracy: 0.638556, val accuracy: 0.634000\n",
      "Loss: 51.889163, Train accuracy: 0.649111, val accuracy: 0.622000\n",
      "Model 0.00055-0.01-0.9-128-5-256\n",
      "Loss: 89.418576, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 70.699551, Train accuracy: 0.286889, val accuracy: 0.297000\n",
      "Loss: 59.241859, Train accuracy: 0.446111, val accuracy: 0.478000\n",
      "Loss: 58.296756, Train accuracy: 0.547111, val accuracy: 0.546000\n",
      "Loss: 61.706880, Train accuracy: 0.603222, val accuracy: 0.596000\n",
      "Model 0.00055-0.001-0.9-64-5-128\n",
      "Loss: 88.004120, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 71.948482, Train accuracy: 0.394444, val accuracy: 0.404000\n",
      "Loss: 59.247694, Train accuracy: 0.524222, val accuracy: 0.533000\n",
      "Loss: 53.543872, Train accuracy: 0.640667, val accuracy: 0.613000\n",
      "Loss: 42.513902, Train accuracy: 0.683778, val accuracy: 0.650000\n",
      "Model 0.00055-0.001-0.9-64-5-256\n",
      "Loss: 89.757154, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 79.389508, Train accuracy: 0.291222, val accuracy: 0.295000\n",
      "Loss: 67.714992, Train accuracy: 0.467889, val accuracy: 0.460000\n",
      "Loss: 39.350385, Train accuracy: 0.571889, val accuracy: 0.570000\n",
      "Loss: 32.823230, Train accuracy: 0.639556, val accuracy: 0.611000\n",
      "Model 0.00055-0.001-0.9-128-5-128\n",
      "Loss: 89.682140, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 76.762085, Train accuracy: 0.397556, val accuracy: 0.397000\n",
      "Loss: 54.691367, Train accuracy: 0.547889, val accuracy: 0.536000\n",
      "Loss: 60.631911, Train accuracy: 0.624444, val accuracy: 0.614000\n",
      "Loss: 44.119949, Train accuracy: 0.674778, val accuracy: 0.641000\n",
      "Model 0.00055-0.001-0.9-128-5-256\n",
      "Loss: 89.065496, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 81.063857, Train accuracy: 0.303444, val accuracy: 0.311000\n",
      "Loss: 65.221760, Train accuracy: 0.493111, val accuracy: 0.476000\n",
      "Loss: 54.872983, Train accuracy: 0.607333, val accuracy: 0.595000\n",
      "Loss: 35.895350, Train accuracy: 0.636556, val accuracy: 0.612000\n",
      "Model 0.00055-0.0001-0.9-64-5-128\n",
      "Loss: 91.091588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 81.926082, Train accuracy: 0.381889, val accuracy: 0.377000\n",
      "Loss: 51.102935, Train accuracy: 0.542000, val accuracy: 0.536000\n",
      "Loss: 47.225721, Train accuracy: 0.626333, val accuracy: 0.620000\n",
      "Loss: 39.670505, Train accuracy: 0.663222, val accuracy: 0.642000\n",
      "Model 0.00055-0.0001-0.9-64-5-256\n",
      "Loss: 93.237349, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 83.192447, Train accuracy: 0.294111, val accuracy: 0.298000\n",
      "Loss: 58.372868, Train accuracy: 0.498444, val accuracy: 0.487000\n",
      "Loss: 59.045607, Train accuracy: 0.601222, val accuracy: 0.607000\n",
      "Loss: 46.870430, Train accuracy: 0.652667, val accuracy: 0.623000\n",
      "Model 0.00055-0.0001-0.9-128-5-128\n",
      "Loss: 87.231070, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 60.530341, Train accuracy: 0.413889, val accuracy: 0.396000\n",
      "Loss: 48.570904, Train accuracy: 0.519778, val accuracy: 0.519000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 64.530261, Train accuracy: 0.584333, val accuracy: 0.568000\n",
      "Loss: 47.654621, Train accuracy: 0.666000, val accuracy: 0.656000\n",
      "Model 0.00055-0.0001-0.9-128-5-256\n",
      "Loss: 84.737732, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 80.143335, Train accuracy: 0.297333, val accuracy: 0.310000\n",
      "Loss: 55.929448, Train accuracy: 0.507222, val accuracy: 0.504000\n",
      "Loss: 47.384593, Train accuracy: 0.567667, val accuracy: 0.574000\n",
      "Loss: 42.229244, Train accuracy: 0.640111, val accuracy: 0.614000\n",
      "Model 0.001-0.01-0.9-64-5-128\n",
      "Loss: 78.597055, Train accuracy: 0.269111, val accuracy: 0.282000\n",
      "Loss: 64.529624, Train accuracy: 0.479333, val accuracy: 0.478000\n",
      "Loss: 58.038125, Train accuracy: 0.572222, val accuracy: 0.551000\n",
      "Loss: 51.643723, Train accuracy: 0.609778, val accuracy: 0.607000\n",
      "Loss: 36.259321, Train accuracy: 0.640111, val accuracy: 0.613000\n",
      "Model 0.001-0.01-0.9-64-5-256\n",
      "Loss: 91.911601, Train accuracy: 0.208222, val accuracy: 0.213000\n",
      "Loss: 71.508331, Train accuracy: 0.387000, val accuracy: 0.401000\n",
      "Loss: 90.103878, Train accuracy: 0.436778, val accuracy: 0.430000\n",
      "Loss: 4354.672007, Train accuracy: 0.207222, val accuracy: 0.213000\n",
      "Loss: inf, Train accuracy: 0.066556, val accuracy: 0.064000\n",
      "Model 0.001-0.01-0.9-128-5-128\n",
      "Loss: 78.968965, Train accuracy: 0.277444, val accuracy: 0.287000\n",
      "Loss: 67.114376, Train accuracy: 0.496444, val accuracy: 0.487000\n",
      "Loss: 38.991709, Train accuracy: 0.553000, val accuracy: 0.547000\n",
      "Loss: 45.666147, Train accuracy: 0.635556, val accuracy: 0.631000\n",
      "Loss: 33.268519, Train accuracy: 0.669333, val accuracy: 0.637000\n",
      "Model 0.001-0.01-0.9-128-5-256\n",
      "Loss: 90.592649, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Loss: 69.905668, Train accuracy: 0.443333, val accuracy: 0.459000\n",
      "Loss: 66.187120, Train accuracy: 0.414889, val accuracy: 0.440000\n",
      "Loss: 1526.466969, Train accuracy: 0.178889, val accuracy: 0.182000\n",
      "Loss: inf, Train accuracy: 0.172778, val accuracy: 0.171000\n",
      "Model 0.001-0.001-0.9-64-5-128\n",
      "Loss: 86.832645, Train accuracy: 0.290667, val accuracy: 0.302000\n",
      "Loss: 61.867186, Train accuracy: 0.477889, val accuracy: 0.505000\n",
      "Loss: 62.015001, Train accuracy: 0.575000, val accuracy: 0.562000\n",
      "Loss: 50.645410, Train accuracy: 0.626889, val accuracy: 0.575000\n",
      "Loss: 64.876782, Train accuracy: 0.618778, val accuracy: 0.576000\n",
      "Model 0.001-0.001-0.9-64-5-256\n",
      "Loss: 86.828708, Train accuracy: 0.212778, val accuracy: 0.223000\n",
      "Loss: 62.019407, Train accuracy: 0.378667, val accuracy: 0.376000\n",
      "Loss: 952.556071, Train accuracy: 0.137000, val accuracy: 0.144000\n",
      "Loss: inf, Train accuracy: 0.070111, val accuracy: 0.066000\n",
      "Loss: inf, Train accuracy: 0.133778, val accuracy: 0.140000\n",
      "Model 0.001-0.001-0.9-128-5-128\n",
      "Loss: 79.173397, Train accuracy: 0.273222, val accuracy: 0.276000\n",
      "Loss: 55.559171, Train accuracy: 0.457222, val accuracy: 0.439000\n",
      "Loss: 73.625993, Train accuracy: 0.564333, val accuracy: 0.524000\n",
      "Loss: 32.897753, Train accuracy: 0.533556, val accuracy: 0.513000\n",
      "Loss: 38.918910, Train accuracy: 0.648889, val accuracy: 0.619000\n",
      "Model 0.001-0.001-0.9-128-5-256\n",
      "Loss: 91.214165, Train accuracy: 0.228333, val accuracy: 0.232000\n",
      "Loss: 85.342594, Train accuracy: 0.373556, val accuracy: 0.391000\n",
      "Loss: 39.282362, Train accuracy: 0.457444, val accuracy: 0.463000\n",
      "Loss: 1091.758081, Train accuracy: 0.232556, val accuracy: 0.203000\n",
      "Loss: inf, Train accuracy: 0.198667, val accuracy: 0.207000\n",
      "Model 0.001-0.0001-0.9-64-5-128\n",
      "Loss: 87.009077, Train accuracy: 0.248333, val accuracy: 0.257000\n",
      "Loss: 50.100103, Train accuracy: 0.505889, val accuracy: 0.486000\n",
      "Loss: 43.837362, Train accuracy: 0.563889, val accuracy: 0.566000\n",
      "Loss: 48.710110, Train accuracy: 0.605000, val accuracy: 0.581000\n",
      "Loss: 37.859077, Train accuracy: 0.669000, val accuracy: 0.639000\n",
      "Model 0.001-0.0001-0.9-64-5-256\n",
      "Loss: 88.616251, Train accuracy: 0.200000, val accuracy: 0.208000\n",
      "Loss: 62.207540, Train accuracy: 0.388667, val accuracy: 0.392000\n",
      "Loss: 44.389807, Train accuracy: 0.542333, val accuracy: 0.524000\n",
      "Loss: 50.057346, Train accuracy: 0.552667, val accuracy: 0.546000\n",
      "Loss: 73.813526, Train accuracy: 0.525889, val accuracy: 0.540000\n",
      "Model 0.001-0.0001-0.9-128-5-128\n",
      "Loss: 87.381332, Train accuracy: 0.249333, val accuracy: 0.259000\n",
      "Loss: 73.357534, Train accuracy: 0.538444, val accuracy: 0.531000\n",
      "Loss: 52.973363, Train accuracy: 0.581000, val accuracy: 0.553000\n",
      "Loss: 48.157814, Train accuracy: 0.651111, val accuracy: 0.632000\n",
      "Loss: 63.499972, Train accuracy: 0.628889, val accuracy: 0.601000\n",
      "Model 0.001-0.0001-0.9-128-5-256\n",
      "Loss: 83.308141, Train accuracy: 0.208222, val accuracy: 0.216000\n",
      "Loss: 82.455810, Train accuracy: 0.406000, val accuracy: 0.422000\n",
      "Loss: 1071.980300, Train accuracy: 0.153556, val accuracy: 0.161000\n",
      "Loss: inf, Train accuracy: 0.141556, val accuracy: 0.132000\n",
      "Loss: inf, Train accuracy: 0.085778, val accuracy: 0.067000\n",
      "best validation accuracy achieved: 0.656000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "learning_rates = np.linspace(1e-4, 1e-3, 3)\n",
    "reg_strength = [1e-2, 1e-3, 1e-4]\n",
    "momentum = [0.9]\n",
    "hidden_layer_size = [64, 128]\n",
    "num_epochs = [5]\n",
    "batch_size = [128, 256]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "best_params = \"\"\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strength:\n",
    "        for mom in momentum:\n",
    "            for hl_size in hidden_layer_size:\n",
    "                for num_ep in num_epochs:\n",
    "                    for b_size in batch_size:\n",
    "                        print(f\"Model {lr}-{reg}-{lr_dec}-{hl_size}-{num_ep}-{b_size}\")\n",
    "                        model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hlsize, reg = reg)\n",
    "                        dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "                        trainer = Trainer(model, dataset, MomentumSGD(mom), learning_rate=lr, num_epochs=num_ep, batch_size=b_size)\n",
    "                        model_loss_history, model_train_history, model_val_history = trainer.fit()\n",
    "                        if(model_val_history[-1] > best_val_accuracy):\n",
    "                            best_val_accuracy = model_val_history[-1]\n",
    "                            best_classifier = model\n",
    "                            loss_history = model_loss_history\n",
    "                            train_history = model_train_history\n",
    "                            val_history = model_val_history\n",
    "                            best_params = f\"Model {lr}-{reg}-{lr_dec}-{hl_size}-{num_ep}-{b_size}\"\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model 0.00055-0.0001-0.9-128-5-128'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0.0006-0.0001-0.9-128-30-128\n",
      "Loss: 87.901516, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 62.494070, Train accuracy: 0.425556, val accuracy: 0.423000\n",
      "Loss: 61.226248, Train accuracy: 0.546889, val accuracy: 0.554000\n",
      "Loss: 44.356144, Train accuracy: 0.614889, val accuracy: 0.608000\n",
      "Loss: 67.966325, Train accuracy: 0.628444, val accuracy: 0.600000\n",
      "Loss: 33.798349, Train accuracy: 0.721444, val accuracy: 0.674000\n",
      "Loss: 46.346090, Train accuracy: 0.716000, val accuracy: 0.667000\n",
      "Loss: 47.399194, Train accuracy: 0.715889, val accuracy: 0.666000\n",
      "Loss: 54.773664, Train accuracy: 0.709889, val accuracy: 0.647000\n",
      "Loss: 34.853109, Train accuracy: 0.795444, val accuracy: 0.719000\n",
      "Loss: 42.264359, Train accuracy: 0.752889, val accuracy: 0.693000\n",
      "Loss: 26.425315, Train accuracy: 0.778444, val accuracy: 0.686000\n",
      "Loss: 21.115961, Train accuracy: 0.821222, val accuracy: 0.725000\n",
      "Loss: 28.758397, Train accuracy: 0.787667, val accuracy: 0.683000\n",
      "Loss: 17.732336, Train accuracy: 0.834778, val accuracy: 0.722000\n",
      "Loss: 24.417138, Train accuracy: 0.800333, val accuracy: 0.687000\n",
      "Loss: 20.931127, Train accuracy: 0.860667, val accuracy: 0.733000\n",
      "Loss: 22.221419, Train accuracy: 0.819778, val accuracy: 0.701000\n",
      "Loss: 19.765668, Train accuracy: 0.882556, val accuracy: 0.727000\n",
      "Loss: 12.411943, Train accuracy: 0.890333, val accuracy: 0.751000\n",
      "Loss: 17.089013, Train accuracy: 0.870222, val accuracy: 0.728000\n",
      "Loss: 11.717125, Train accuracy: 0.839111, val accuracy: 0.701000\n",
      "Loss: 10.446028, Train accuracy: 0.873333, val accuracy: 0.718000\n",
      "Loss: 17.086172, Train accuracy: 0.892333, val accuracy: 0.735000\n",
      "Loss: 25.240537, Train accuracy: 0.880667, val accuracy: 0.714000\n",
      "Loss: 32.905745, Train accuracy: 0.871000, val accuracy: 0.715000\n",
      "Loss: 9.955057, Train accuracy: 0.876111, val accuracy: 0.730000\n",
      "Loss: 10.504799, Train accuracy: 0.882667, val accuracy: 0.732000\n",
      "Loss: 7.586073, Train accuracy: 0.920667, val accuracy: 0.744000\n",
      "Loss: 10.121268, Train accuracy: 0.924556, val accuracy: 0.752000\n",
      "best validation accuracy achieved: 0.752000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "learning_rates = [0.0006]\n",
    "reg_strength = [0.0001]\n",
    "momentum = [0.9]\n",
    "hidden_layer_size = [128]\n",
    "num_epochs = [30]\n",
    "batch_size = [128]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "best_params = \"\"\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in reg_strength:\n",
    "        for mom in momentum:\n",
    "            for hl_size in hidden_layer_size:\n",
    "                for num_ep in num_epochs:\n",
    "                    for b_size in batch_size:\n",
    "                        print(f\"Model {lr}-{reg}-{lr_dec}-{hl_size}-{num_ep}-{b_size}\")\n",
    "                        model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hlsize, reg = reg)\n",
    "                        dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "                        trainer = Trainer(model, dataset, MomentumSGD(mom), learning_rate=lr, num_epochs=num_ep, batch_size=b_size)\n",
    "                        model_loss_history, model_train_history, model_val_history = trainer.fit()\n",
    "                        if(model_val_history[-1] > best_val_accuracy):\n",
    "                            best_val_accuracy = model_val_history[-1]\n",
    "                            best_classifier = model\n",
    "                            loss_history = model_loss_history\n",
    "                            train_history = model_train_history\n",
    "                            val_history = model_val_history\n",
    "                            best_params = f\"Model {lr}-{reg}-{lr_dec}-{hl_size}-{num_ep}-{b_size}\"\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x126837d6d08>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.729000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
